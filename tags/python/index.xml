<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on Feng</title><link>https://alongwy.top/tags/python/</link><description>Recent content in Python on Feng</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 28 Aug 2021 11:35:41 +0000</lastBuildDate><atom:link href="https://alongwy.top/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Language Technology Platform</title><link>https://alongwy.top/projects/creations/language-technology-platform/</link><pubDate>Sat, 28 Aug 2021 11:35:41 +0000</pubDate><guid>https://alongwy.top/projects/creations/language-technology-platform/</guid><description>Intro An open-source neural language technology platform supporting six fundamental Chinese NLP tasks:
lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition) syntactic parsing (dependency parsing) semantic parsing (semantic dependency parsing and semantic role labeling). Quickstart 1 2 3 4 5 6 7 8 9 from ltp import LTP ltp = LTP() # 默认加载 Small 模型 seg, hidden = ltp.seg([&amp;#34;他叫汤姆去拿外衣。&amp;#34;]) pos = ltp.pos(hidden) ner = ltp.</description></item><item><title>N-LTP: A Open-source Neural Chinese Language Technology Platform with Pretrained Models</title><link>https://alongwy.top/publications/n-ltp-a-open-source-neural-chinese-language-technology-platform-with-pretrained-models/</link><pubDate>Sat, 28 Aug 2021 11:00:37 +0000</pubDate><guid>https://alongwy.top/publications/n-ltp-a-open-source-neural-chinese-language-technology-platform-with-pretrained-models/</guid><description>An open-source neural language technology platform supporting six fundamental Chinese NLP tasks:
lexical analysis (Chinese word segmentation, part-of-speech tagging, and named entity recognition) syntactic parsing (dependency parsing) semantic parsing (semantic dependency parsing and semantic role labeling). Unlike the existing state-of-the-art toolkits, such as Stanza, that adopt an independent model for each task, N-LTP adopts the multi-task framework by using a shared pre-trained model, which has the advantage of capturing the shared knowledge across relevant Chinese tasks.</description></item><item><title>HIT-SCIR at MRP 2020: Transition-based Parser and Iterative Inference Parser</title><link>https://alongwy.top/publications/hit-scir-at-mrp-2020-transition-based-parser-and-iterative-inference-parser/</link><pubDate>Tue, 01 Sep 2020 11:00:06 +0000</pubDate><guid>https://alongwy.top/publications/hit-scir-at-mrp-2020-transition-based-parser-and-iterative-inference-parser/</guid><description>This paper describes our submission system (HIT-SCIR) for the CoNLL 2020 shared task: Cross-Framework and Cross-Lingual Meaning Representation Parsing.
The task includes five frameworks for graph-based meaning representations, i.e., UCCA, EDS, PTG, AMR, and DRG.
Our solution consists of two sub-systems:
transition-based parser for Flavor (1) frameworks (UCCA, EDS, PTG) iterative inference parser for Flavor (2) frameworks (DRG, AMR). In the final evaluation, our system is ranked 3rd among the seven team both in Cross-Framework Track and Cross-Lingual Track, with the macro-averaged MRP F1 score of 0.</description></item></channel></rss>